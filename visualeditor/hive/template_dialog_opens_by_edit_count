#!/bin/bash

IFS='-' read -a date <<< $1

hive -e "
WITH all_events AS (
    SELECT
        wiki,
        event.user_editcount,
        event.user_id
    FROM
        event.VisualEditorFeatureUse
    WHERE
        event.feature = 'transclusion'
        AND event.action LIKE 'window-open-%'
        and event.is_oversample = false
        and useragent.is_bot = false
        and year = ${date[0]}
        and month = ${date[1]}
        and day = ${date[2]}
),

bucketed_events AS (
    SELECT
        wiki,
        CASE WHEN user_id = 0 THEN 'anonymous'
            WHEN user_editcount > 1000 THEN '1000+ edits'
            WHEN user_editcount > 100 THEN '100-999 edits'
            WHEN user_editcount > 4 THEN '5-99 edits'
            WHEN user_editcount > 0 THEN '1-4 edits'
            ELSE '0 edits'
        END edit_count_bucket
    FROM
        all_events
)

SELECT
    '$1' AS \`date\`,
    wiki,
    edit_count_bucket,
    -- Compensate for sampling by multiplying by 1 / 6.25% = 16
    COUNT(*) * 16 as template_dialog_opens
FROM
    bucketed_events
GROUP BY
    wiki,
    edit_count_bucket;
" 2> /dev/null | grep -v parquet.hadoop
