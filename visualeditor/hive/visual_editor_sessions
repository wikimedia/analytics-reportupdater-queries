#!/bin/bash

IFS='-' read -a date <<< $1

hive -e "
WITH events AS (
SELECT
    event.editor_interface,
    event.user_id,
    event.user_editcount,
    event.action,
    wiki
FROM
    event.EditAttemptStep
WHERE
    event.action = 'ready'
    AND event.editor_interface IN (
        'visualeditor',
        'wikitext-2017'
    )
    AND event.is_oversample = false
    and year = ${date[0]}
    and month = ${date[1]}
    and day = ${date[2]}
),
bucketed_events AS (
    SELECT
        wiki,
        action,
        CASE WHEN user_id = 0 THEN 'anonymous'
            WHEN user_editcount >= 1000 THEN '1000+ edits'
            WHEN user_editcount >= 100 THEN '100-999 edits'
            WHEN user_editcount >= 5 THEN '5-99 edits'
            WHEN user_editcount >= 1 THEN '1-4 edits'
            ELSE '0 edits'
        END AS edit_count_bucket
    FROM
        events
)

SELECT
    '$1' AS \`date\`,
    wiki,
    edit_count_bucket,
    -- Multiply by 16 to compensate for sampling.
    COUNT(*) * 16 AS visual_editor_sessions
FROM
    bucketed_events
GROUP BY
    wiki,
    edit_count_bucket;
" 2> /dev/null | grep -v parquet.hadoop
