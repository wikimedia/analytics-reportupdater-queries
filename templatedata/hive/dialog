#!/bin/bash
hive -e "
WITH events AS (
    SELECT
        wiki,
        event.user_id,
        event.user_edit_count,
        event.action
    FROM
        event.TemplateDataEditor
    WHERE
        year = cast(split('$1', '-')[0] as int)
        AND month = cast(split('$1', '-')[1] as int)
        AND day = cast(split('$1', '-')[2] as int)
),
bucketed_events AS (
    SELECT
        wiki,
        action,
        CASE WHEN user_id = 0 THEN 'anonymous'
            WHEN user_edit_count > 10000 THEN 'over10k'
            WHEN user_edit_count > 1000 THEN 'over1k'
            WHEN user_edit_count > 100 THEN 'over100'
            WHEN user_edit_count > 10 THEN 'over10'
            ELSE 'under11'
        END AS edit_count_bucket
    FROM
        events
),
metrics AS (
    SELECT
        wiki,
        edit_count_bucket,
        SUM(
            CASE
                WHEN action = 'dialog-open-create' THEN 1
                ELSE 0
            END
        ) AS dialog_open_create,
        SUM(
            CASE
                WHEN action = 'dialog-open-edit' THEN 1
                ELSE 0
            END
        ) AS dialog_open_edit,
        SUM(
            CASE
                WHEN action = 'save-page-create' THEN 1
                ELSE 0
            END
        ) AS save_dialog_create,
        SUM(
            CASE
                WHEN action = 'save-page-edit' THEN 1
                ELSE 0
            END
        ) AS save_dialog_edit
    FROM
        bucketed_events
    GROUP BY
        wiki,
        edit_count_bucket
)

SELECT
    '$1' AS report_date,
    wiki,
    edit_count_bucket,
    save_dialog_create AS create_and_save,
    (dialog_open_create - save_dialog_create) AS create_and_abandon,
    save_dialog_edit AS edit_and_save,
    (dialog_open_edit - save_dialog_edit) AS edit_and_abandon
FROM
    metrics;
" 2> /dev/null | grep -v parquet.hadoop
