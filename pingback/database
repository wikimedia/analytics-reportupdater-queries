#!/bin/bash
hive -e "
WITH numbered AS (
    SELECT
        event.\`database\` AS event_database,
        ROW_NUMBER() OVER (
            PARTITION BY wiki
            ORDER BY dt DESC
        ) AS row_num
    FROM
        event_sanitized.mediawikipingback
    WHERE
        CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) >= date_sub('$1', 23) AND
        CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) < '$2' AND
        (event.\`database\` LIKE 'mysql%' OR NOT (
            event.MediaWiki LIKE '1.31.0%' OR
            event.MediaWiki = '1.32.0-alpha'
        )) AND
        event.\`database\` != ''
)
SELECT
    '$1' AS report_date,
    SUM(IF(event_database LIKE 'mysql%', 1, 0)) AS \`mysql\`,
    SUM(IF(event_database = 'sqlite', 1, 0)) AS \`sqlite\`,
    SUM(IF(event_database = 'postgres', 1, 0)) AS \`postgres\`,
    SUM(IF(event_database = 'mssql', 1, 0)) AS \`mssql\`,
    SUM(IF(event_database NOT LIKE 'mysql%' AND
        event_database != 'sqlite' AND
        event_database != 'postgres' AND
        event_database != 'mssql', 1, 0)) AS \`Other\`
FROM numbered
WHERE row_num = 1
;
" 2> /dev/null | grep -v parquet.hadoop
