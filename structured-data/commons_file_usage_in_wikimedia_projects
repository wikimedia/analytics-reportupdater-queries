#!/bin/bash
# see https://phabricator.wikimedia.org/T247099
# number of total 'content' pages across the wikimedia projects using Wikidata
# excluding sitelinks

MONTH=$(echo $1 | cut -c1-7)
hive -e "


use wmf_raw;
set hive.mapred.mode=nonstrict;

WITH

    wiki_content_namespaces as (
        select
            dbname,
            namespace
        FROM
            wmf_raw.mediawiki_project_namespace_map
        WHERE
            namespace_is_content = 1
            AND snapshot = '${MONTH}'
    ),

    imagelinks_commons_files as (
        SELECT
            COUNT(DISTINCT il_to) AS num_commons_files_used_content_pages
        FROM
            wmf_raw.mediawiki_imagelinks as m
            INNER JOIN wiki_content_namespaces AS ns
                ON ( ns.namespace = m.il_from_namespace)
        WHERE
            m.snapshot = '${MONTH}'
    ),

    page_history_commons_files as (
        SELECT
            COUNT(distinct page_id) AS num_files_on_commons
        FROM
            wmf.mediawiki_page_history
        WHERE
            snapshot='${MONTH}' AND NOT page_is_redirect 
            AND not page_is_deleted 
            AND page_namespace =6 AND wiki_db='commonswiki'
    )

    SELECT
        '$1' as date,
        num_commons_files_used_content_pages,
        num_files_on_commons,
   	(num_commons_files_used_content_pages/num_files_on_commons) as percentage 
   FROM
        page_history_commons_files,imagelinks_commons_files
    ;



" 2> /dev/null | grep -v parquet.hadoop

