#!/bin/bash
hive -e "
WITH
    slice AS (
        SELECT
            wiki_db,
            SUM(IF(network_origin='wikimedia_labs', edit_count, 0)) AS wmcs_edits,
            SUM(edit_count) AS total_edits,
            ROUND(SUM(IF(network_origin='wikimedia_labs', edit_count, 0)) / SUM(edit_count), 3) AS wmcs_percent
        FROM wmf.editors_daily
        WHERE
            month = substr('$1', 1, 7)
        GROUP BY
            wiki_db
    )

SELECT
    '$1' AS \`date\`,
    'TOTAL' AS wiki_db,
    ROUND(SUM(wmcs_edits) / SUM(total_edits), 3) AS wmcs_percent
FROM slice

UNION ALL

SELECT
    '$1' AS \`date\`,
    wiki_db,
    wmcs_percent
FROM slice

ORDER BY
    wiki_db
LIMIT 10000
;
" 2> /dev/null | grep -v parquet.hadoop | python $3/dynamic_pivot.py
